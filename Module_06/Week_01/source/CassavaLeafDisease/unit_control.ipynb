{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = {\n",
    "    'train': './data/cassavaleafdata/train',\n",
    "    'test': './data/cassavaleafdata/test',\n",
    "    'val': './data/cassavaleafdata/validation'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image from path\n",
    "def loader(path):\n",
    "    return Image.open(path)\n",
    "\n",
    "img_size = 150\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.ImageFolder(\n",
    "    root=data_paths['train'],\n",
    "    loader=loader,\n",
    "    transform=train_transforms\n",
    ")\n",
    "valid_data = datasets.ImageFolder(\n",
    "    root=data_paths['val'],\n",
    "    transform=train_transforms\n",
    ")\n",
    "test_data = datasets.ImageFolder(\n",
    "    root=data_paths['test'],\n",
    "    transform=train_transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToPILImage\n",
    "\n",
    "count = 0\n",
    "for index, (image, label) in enumerate(test_data):\n",
    "    image = ToPILImage()(image)\n",
    "    image.save(f'./inference/images/{index}.png')\n",
    "    count += 1\n",
    "    if count == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2label = {\n",
    "  0: 'cbb',\n",
    "  1: 'cbsd',\n",
    "  2: 'cgm',\n",
    "  3: 'cmd',\n",
    "  4: 'healthy',\n",
    "}\n",
    "\n",
    "class LeNetClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=6, kernel_size=5, padding='same'\n",
    "        )\n",
    "        self.avgpool1 = nn.AvgPool2d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.avgpool2 = nn.AvgPool2d(kernel_size=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc_1 = nn.Linear(16 * 35 * 35, 120)\n",
    "        self.fc_2 = nn.Linear(120, 84)\n",
    "        self.fc_3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.conv1(inputs)\n",
    "        outputs = self.avgpool1(outputs)\n",
    "        outputs = F.relu(outputs)\n",
    "        outputs = self.conv2(outputs)\n",
    "        outputs = self.avgpool2(outputs)\n",
    "        outputs = F.relu(outputs)\n",
    "        outputs = self.flatten(outputs)\n",
    "        outputs = self.fc_1(outputs)\n",
    "        outputs = self.fc_2(outputs)\n",
    "        outputs = self.fc_3(outputs)\n",
    "        return outputs\n",
    "\n",
    "def load_model(model_path, num_classes=5):\n",
    "    lenet_model = LeNetClassifier(num_classes)\n",
    "    lenet_model.load_state_dict(torch.load(model_path, weights_only=True, map_location=torch.device('cpu')))\n",
    "    lenet_model.eval()\n",
    "    return lenet_model\n",
    "model = load_model('./model/lenet_model.pt')\n",
    "\n",
    "def inference(image, model):\n",
    "  img_size = 150\n",
    "  img_transform = transforms.Compose([\n",
    "      transforms.Resize((img_size, img_size)),\n",
    "      transforms.ToTensor(),\n",
    "  ])\n",
    "  img_new = img_transform(image)\n",
    "  img_new = torch.unsqueeze(img_new, 0)\n",
    "  with torch.no_grad():\n",
    "      predictions = model(img_new)\n",
    "  preds = nn.Softmax(dim=1)(predictions)\n",
    "  p_max, yhat = torch.max(preds.data, 1)\n",
    "  return p_max.item()*100, yhat.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted 0: cmd with confidence 39.78%, true label: cbb\n",
      "Predicted 1: cbsd with confidence 40.04%, true label: cbb\n",
      "Predicted 2: cmd with confidence 38.16%, true label: cbb\n",
      "Predicted 3: cmd with confidence 52.44%, true label: cbb\n",
      "Predicted 4: cmd with confidence 47.05%, true label: cbb\n",
      "Predicted 5: cbsd with confidence 45.49%, true label: cbb\n",
      "Predicted 6: cbsd with confidence 34.01%, true label: cbb\n",
      "Predicted 7: cmd with confidence 51.32%, true label: cbb\n",
      "Predicted 8: cmd with confidence 49.87%, true label: cbb\n",
      "Predicted 9: cmd with confidence 72.97%, true label: cbb\n"
     ]
    }
   ],
   "source": [
    "for index in range(10):\n",
    "    image = Image.open(f'./inference/images/{index}.png')\n",
    "    \n",
    "    confidence, predicted = inference(image, model)\n",
    "    \n",
    "    print(f'Predicted {index}: {idx2label[predicted]} with confidence {confidence:.2f}%, true label: {idx2label[test_data[index][1]]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visualize_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
